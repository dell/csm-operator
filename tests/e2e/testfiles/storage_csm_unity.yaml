apiVersion: storage.dell.com/v1
kind: ContainerStorageModule
metadata:
  name: unity
  namespace: unity
spec:
  driver:
    csiDriverType: "unity"
    csiDriverSpec:
      # fsGroupPolicy: Defines if the underlying volume supports changing ownership and permission of the volume before being mounted.
      # Allowed values: ReadWriteOnceWithFSType, File , None
      # Default value: ReadWriteOnceWithFSType
      fSGroupPolicy: "ReadWriteOnceWithFSType"
      # storageCapacity: Helps the scheduler to schedule the pod on a node satisfying the topology constraints, only if the requested capacity is available on the storage array
      # Allowed values:
      #   true: enable storage capacity tracking
      #   false: disable storage capacity tracking
      storageCapacity: true
    configVersion: v2.15.0
    # Controller count
    replicas: 2
    dnsPolicy: ClusterFirstWithHostNet
    forceRemoveDriver: true
    common:
      image: "quay.io/dell/container-storage-modules/csi-unity:nightly"
      imagePullPolicy: Always
      envs:
        - name: X_CSI_UNITY_ALLOW_MULTI_POD_ACCESS
          value: "false"
        - name: X_CSI_EPHEMERAL_STAGING_PATH
          value: "/var/lib/kubelet/plugins/kubernetes.io/csi/pv/"
        - name: X_CSI_ISCSI_CHROOT
          value: "/noderoot"
        - name: X_CSI_UNITY_SYNC_NODEINFO_INTERVAL
          value: "15"
        - name: KUBELET_CONFIG_DIR
          value: /var/lib/kubelet
        - name: CSI_LOG_LEVEL
          value: debug
        - name: TENANT_NAME
          value: ""
    sideCars:
      # 'csivol' represents a string prepended to each volume created by the CSI driver
      - name: provisioner
        args: ["--volume-name-prefix=csivol"]
      # health monitor is disabled by default, refer to driver documentation before enabling it
      - name: external-health-monitor
        enabled: false
        args: ["--monitor-interval=60s"]
        # Uncomment the following to configure how often external-provisioner polls the driver to detect changed capacity
        # Configure when the storageCapacity is set as "true"
        # Allowed values: 1m,2m,3m,...,10m,...,60m etc. Default value: 5m
        # - name: provisioner
        #  args: ["--capacity-poll-interval=5m"]
    controller:
      envs:
        # X_CSI_HEALTH_MONITOR_ENABLED: Enable/Disable health monitor of CSI volumes from Controller plugin - volume condition.
        # Install the 'external-health-monitor' sidecar accordingly.
        # Allowed values:
        #   true: enable checking of health condition of CSI volumes
        #   false: disable checking of health condition of CSI volumes
        # Default value: false
        - name: X_CSI_HEALTH_MONITOR_ENABLED
          value: "false"
      nodeSelector:
      # Uncomment if nodes you wish to use have the node-role.kubernetes.io/control-plane taint
      #  node-role.kubernetes.io/control-plane: ""

      # tolerations: Define tolerations for the controllers, if required.
      # Leave as blank to install controller on worker nodes
      # Default value: None
      tolerations:
      # Uncomment if nodes you wish to use have the node-role.kubernetes.io/control-plane taint
      # - key: "node-role.kubernetes.io/control-plane"
      #   operator: "Exists"
      #   effect: "NoSchedule"
    node:
      envs:
        # X_CSI_HEALTH_MONITOR_ENABLED: Enable/Disable health monitor of CSI volumes from node plugin - volume usage
        # Allowed values:
        #   true: enable checking of health condition of CSI volumes
        #   false: disable checking of health condition of CSI volumes
        # Default value: false
        - name: X_CSI_HEALTH_MONITOR_ENABLED
          value: "false"
      # nodeSelector: Define node selection constraints for node pods.
      # For the pod to be eligible to run on a node, the node must have each
      # of the indicated key-value pairs as labels.
      # Leave as blank to consider all nodes
      # Allowed values: map of key-value pairs
      # Default value: None
      nodeSelector:
      # Uncomment if nodes you wish to use have the node-role.kubernetes.io/control-plane taint
      #  node-role.kubernetes.io/control-plane: ""

      # tolerations: Define tolerations for the controllers, if required.
      # Leave as blank to install controller on worker nodes
      # Default value: None
      tolerations:
# Uncomment if nodes you wish to use have the node-role.kubernetes.io/control-plane taint
# - key: "node-role.kubernetes.io/control-plane"
#   operator: "Exists"
#   effect: "NoSchedule"
